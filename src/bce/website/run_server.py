#!/usr/bin/env python3
"""
Launch script for the BCE Prediction Web Server
"""

import argparse
import uvicorn
import sys
import time
import torch
from pathlib import Path

def preload_model(device_id=-1, model_path=None, verbose=True):
    """
    é¢„åŠ è½½ReCEPæ¨¡å‹ä»¥å‡å°‘é¦–æ¬¡è¯·æ±‚å»¶è¿Ÿ
    """
    try:
        if verbose:
            print("ğŸ”„ Preloading ReCEP model...")
        
        # Add project root to path
        script_dir = Path(__file__).parent
        project_root = script_dir.parents[2]
        sys.path.insert(0, str(project_root))
        
        from bce.model.ReCEP import ReCEP
        from bce.utils.constants import BASE_DIR
        
        # è®¾ç½®è®¾å¤‡
        if device_id >= 0 and torch.cuda.is_available():
            device = torch.device(f"cuda:{device_id}")
            if verbose:
                print(f"ğŸ¯ Using GPU: {torch.cuda.get_device_name(device_id)}")
        else:
            device = torch.device("cpu")
            if verbose:
                print("ğŸ¯ Using CPU")
        
        # ä½¿ç”¨é»˜è®¤æ¨¡å‹è·¯å¾„å¦‚æœæœªæŒ‡å®š
        if model_path is None:
            model_path = f"{BASE_DIR}/models/ReCEP/20250626_110438/best_mcc_model.bin"
        
        start_time = time.time()
        
        # åŠ è½½æ¨¡å‹
        model, threshold = ReCEP.load(model_path, device=device, strict=False, verbose=False)
        model.eval()
        
        # é¢„çƒ­GPUï¼ˆå¦‚æœä½¿ç”¨GPUï¼‰
        if device.type == 'cuda':
            # åˆ›å»ºä¸€ä¸ªå°çš„æµ‹è¯•å¼ é‡æ¥é¢„çƒ­GPU
            dummy_tensor = torch.randn(10, 512).to(device)
            with torch.no_grad():
                _ = dummy_tensor.sum()
            del dummy_tensor
            torch.cuda.synchronize()
        
        load_time = time.time() - start_time
        
        if verbose:
            print(f"âœ… Model preloaded successfully in {load_time:.2f}s")
            print(f"ğŸ“ Model threshold: {threshold:.4f}")
        
        return True
        
    except Exception as e:
        if verbose:
            print(f"âš ï¸  Model preload failed: {str(e)}")
            print("   Server will load model on first request")
        return False

def main():
    parser = argparse.ArgumentParser(description="Launch BCE Prediction Web Server")
    parser.add_argument("--host", default="0.0.0.0", help="Host to bind to (default: 0.0.0.0)")
    parser.add_argument("--port", type=int, default=8000, help="Port to bind to (default: 8000)")
    parser.add_argument("--reload", action="store_true", help="Enable auto-reload for development")
    parser.add_argument("--workers", type=int, default=1, help="Number of worker processes")
    parser.add_argument("--log-level", default="info", choices=["debug", "info", "warning", "error", "critical"],
                       help="Log level (default: info)")
    parser.add_argument("--preload", action="store_true", default=True, help="Preload model on startup (default: True)")
    parser.add_argument("--no-preload", action="store_true", help="Skip model preloading")
    parser.add_argument("--device-id", type=int, default=-1, help="Device ID for model preloading (default: -1 for CPU)")
    parser.add_argument("--model-path", type=str, default=None, help="Custom model path for preloading")
    
    args = parser.parse_args()
    
    # Ensure we're in the correct directory
    script_dir = Path(__file__).parent
    sys.path.insert(0, str(script_dir))
    
    # Change to the website directory to ensure relative imports work
    import os
    original_cwd = os.getcwd()
    os.chdir(script_dir)
    
    print(f"ğŸ“ Working directory: {script_dir}")
    print(f"ğŸ Python path includes: {script_dir}")
    
    print(f"ğŸš€ Starting BCE Prediction Server...")
    print(f"ğŸ“ Server will be available at: http://{args.host}:{args.port}")
    print(f"ğŸ“– API documentation at: http://{args.host}:{args.port}/docs")
    print(f"ğŸ”„ Auto-reload: {'enabled' if args.reload else 'disabled'}")
    
    # æ¨¡å‹é¢„åŠ è½½
    should_preload = args.preload and not args.no_preload and not args.reload
    if should_preload:
        success = preload_model(
            device_id=args.device_id,
            model_path=args.model_path,
            verbose=True
        )
        if success:
            print("ğŸ‰ Server ready for fast predictions!")
        else:
            print("âš ï¸  Server starting without preload")
    else:
        if args.reload:
            print("â„¹ï¸  Skipping preload in reload mode")
        else:
            print("â„¹ï¸  Skipping model preload (use --preload to enable)")
    
    print("-" * 50)
    
    # Run the server - Use direct import to avoid module resolution issues
    print("ğŸ”§ Starting server with direct import method...")
    
    # Ensure the website directory is first in Python path to avoid conflicts
    if str(script_dir) not in sys.path:
        sys.path.insert(0, str(script_dir))
    
    # Remove any conflicting paths that might have main.py
    project_root = script_dir.parents[2]
    if str(project_root) in sys.path:
        sys.path.remove(str(project_root))
    
    print(f"ğŸ” Python path: {sys.path[:3]}...")  # Show first 3 paths
    
    try:
        import main
        print(f"ğŸ“„ Imported main from: {main.__file__}")
        app = main.app
        uvicorn.run(
            app,
            host=args.host,
            port=args.port,
            reload=args.reload,
            workers=args.workers if not args.reload else 1,
            log_level=args.log_level,
            access_log=True
        )
    except Exception as e:
        print(f"âŒ Direct import failed: {str(e)}")
        print("ğŸ’¡ Trying string-based import...")
        
        # Fallback: try string-based import
        try:
            uvicorn.run(
                "main:app",
                host=args.host,
                port=args.port,
                reload=args.reload,
                workers=args.workers if not args.reload else 1,
                log_level=args.log_level,
                access_log=True
            )
        except Exception as e2:
            print(f"âŒ String-based import also failed: {str(e2)}")
            print("ğŸ”§ Please check your environment and dependencies")

if __name__ == "__main__":
    main() 